{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A model that has been linked to the data is called \"the conditioned model\"\n",
    "-  the order in which you place the lines of a @model macro matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Turing \n",
    "using StatsPlots\n",
    "using StatsBase\n",
    "using Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gdemo (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function gdemo(x, y)\n",
    "    s² ~ InverseGamma(2, 3)\n",
    "    m ~ Normal(0, sqrt(s²))\n",
    "    x ~ Normal(m, sqrt(s²))\n",
    "    y ~ Normal(m, sqrt(s²))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Found initial step size\n",
      "│   ϵ = 1.6\n",
      "└ @ Turing.Inference C:\\Users\\axs162731\\.julia\\packages\\Turing\\Gntg0\\src\\inference\\hmc.jl:188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chains MCMC chain (1000×14×1 Array{Float64, 3}):\n",
       "\n",
       "Iterations        = 1:1000\n",
       "Thinning interval = 1\n",
       "Chains            = 1\n",
       "Samples per chain = 1000\n",
       "parameters        = m, s²\n",
       "internals         = acceptance_rate, hamiltonian_energy, hamiltonian_energy_error, is_accept, log_density, lp, max_hamiltonian_energy_error, n_steps, nom_step_size, numerical_error, step_size, tree_depth\n",
       "\n",
       "Summary Statistics\n",
       " \u001b[1m parameters \u001b[0m \u001b[1m    mean \u001b[0m \u001b[1m     std \u001b[0m \u001b[1m naive_se \u001b[0m \u001b[1m    mcse \u001b[0m \u001b[1m      ess \u001b[0m \u001b[1m    rhat \u001b[0m\n",
       " \u001b[90m     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m  Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\n",
       "\n",
       "           m    1.1653    0.8296     0.0262    0.0379   305.8115    0.9990\n",
       "          s²    2.1529    2.0800     0.0658    0.1637   260.5822    0.9997\n",
       "\n",
       "Quantiles\n",
       " \u001b[1m parameters \u001b[0m \u001b[1m    2.5% \u001b[0m \u001b[1m   25.0% \u001b[0m \u001b[1m   50.0% \u001b[0m \u001b[1m   75.0% \u001b[0m \u001b[1m   97.5% \u001b[0m\n",
       " \u001b[90m     Symbol \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m\n",
       "\n",
       "           m   -0.4917    0.6658    1.1920    1.6791    2.7774\n",
       "          s²    0.5882    1.1125    1.5720    2.3858    7.5673\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c1 = sample(gdemo(1.5, 2), SMC(), 1000)\n",
    "#c2 = sample(gdemo(1.5, 2), PG(10), 1000)\n",
    "#c3 = sample(gdemo(1.5, 2), HMC(0.1, 5), 1000)\n",
    "# c4 = sample(gdemo(1.5, 2), Gibbs(PG(10, :m), HMC(0.1, 5, :s)), 1000) - doesn't work\n",
    "# c5 = sample(gdemo(1.5, 2), HMCDA(0.15, 0.65), 1000)\n",
    "c6 = sample(gdemo(1.5, 2), NUTS(0.65), n_chains=3,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeResult with maximized lp of -0.07\n",
       "2-element Named Vector{Float64}\n",
       "A   │ \n",
       "────┼───────\n",
       ":s² │ 0.0625\n",
       ":m  │   1.75"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function gdemo(x)\n",
    "    s² ~ InverseGamma(2, 3)\n",
    "    m ~ Normal(0, sqrt(s²))\n",
    "\n",
    "    for i in eachindex(x)\n",
    "        x[i] ~ Normal(m, sqrt(s²))\n",
    "    end\n",
    "end\n",
    "\n",
    "# Create some data to pass to the model.\n",
    "data = [1.5, 2.0]\n",
    "\n",
    "# Instantiate the gdemo model with our data.\n",
    "model = gdemo(data)\n",
    "# Generate a MLE estimate.\n",
    "mle_estimate = optimize(model, MLE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeResult with maximized lp of -0.07\n",
       "2-element Named Vector{Float64}\n",
       "A   │ \n",
       "────┼───────\n",
       ":s² │ 0.0625\n",
       ":m  │   1.75"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mle_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Named Matrix{Float64}\n",
       "A ╲ B │          :s²            :m\n",
       "──────┼───────────────────────────\n",
       ":s²   │   0.00390625  -7.62307e-14\n",
       ":m    │ -7.62307e-14       0.03125"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informationmatrix(mle_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = Turing.VarInfo(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
